{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with an existing corpus\n",
    "\n",
    "In this notebook, we will work with an existing corpus, in csv format, to draw information from it and do some basic operations with spaCy.\n",
    "\n",
    "Go back to the `spacy_intro.ipynb` notebook for an intro to spaCy and for information on how to iterate through tokens and lemmas. \n",
    "\n",
    "Here, we will work with larger texts, to either create a corpus or work with one that already exists. In the `data/` directory, there is a file called `gnm_articles.csv` that you'll need. \n",
    "\n",
    "Acknowledgements: [Tuomo Hiippala](https://www.mv.helsinki.fi/home/thiippal/), [Programming Historian](https://programminghistorian.org/), [Melanie Walsh](https://melaniewalsh.github.io/Intro-Cultural-Analytics/welcome.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import os\n",
    "import re\n",
    "from pprint import pprint\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with a csv file\n",
    "\n",
    "We will first work with a single file, a part of the [SFU Opinion and Comments Corpus (SOCC)](https://github.com/sfu-discourse-lab/SOCC). The corpus was collected in our lab, the Discourse Processing Lab, for a project on evaluative language in online news comments. It consists of: opinion articles, comments, and annotated comments from the Canadian newspaper _The Globe and Mail_. We'll work with the articles, which should be in the data directory. If not, you can always download the corpus directly from the page above or from its [Kaggle page](https://www.kaggle.com/datasets/mtaboada/sfu-opinion-and-comments-corpus-socc) and save the `gnm_articles.csv` file to your data directory. \n",
    "\n",
    "We will first read the csv file into a pandas dataframe, `socc_df`. You can find out more about the contents of the file with the pandas function `shape()`. Then, we'll print the first few rows and find out what the headers are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csv file into a pandas dataframe\n",
    "\n",
    "socc_df = pd.read_csv('data/gnm_articles.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the number of rows and columns and print them\n",
    "\n",
    "nRow, nCol = socc_df.shape\n",
    "print(f'There are {nRow} rows and {nCol} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the first 5 rows\n",
    "\n",
    "socc_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information about the dataframe\n",
    "\n",
    "From the `shape()` information, we know that the file has 10,339 rows. That is one article per row, with information about the title of the article, the author, the date of publication and the number of comments it received. The comments are stored in a separate file in the [SOCC corpus](https://github.com/sfu-discourse-lab/SOCC).  \n",
    "\n",
    "We can examine the pandas dataframe and figure out, for instance, how many comments articles got. `ncomments` is the number o total comments an article received.  `ntop_level_comments` is how many of them were beginnings of threads (as opposed to replies). \n",
    "\n",
    "You can use `value_counts()` to list characteristics of various columns. Here, we'll do `ncomments` and `author`. I also use `describe()` to give me statistics of how many columns there are, the average, min and max, etc. Note the difference between the output for `describe()` for the comments and for the authors, as the former contains numbers and the latter, strings. \n",
    "\n",
    "You can also get the same information in a bar chart, which here I am limiting to the top 10 categories. But you can change that parameter (`value_counts()[:10]`) to get more bars. Note: if the `.plot()` cells don't show you a bar chart, run them again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "socc_df['ncomments'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "socc_df['ncomments'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "socc_df['author'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "socc_df['author'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "socc_df['ncomments'].value_counts()[:10].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "socc_df['author'].value_counts()[:10].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore articles with many and with zero comments\n",
    "\n",
    "We are going to compare articles that have many comments to those that have none. Let's take a random sample of 100 of each and do a few comparisons.\n",
    "\n",
    "As you saw above, the average number of comments is 64. So let's use that number as the cut-off for articles with many comments. \n",
    "\n",
    "We first copy a part of the original data frame into a new one, selecting only rows where the count of ncomments is higher than 64. If you are curious, that gives us 3,179 articles, with a large spread of how many comments each has. We take a random sample of 100 from those and put the value of the `article_text` column into a string, `many_comments`. \n",
    "\n",
    "Then, we do exactly the same for articles with 0 comments and put them into a different string, `zero_comments`. There are 2,542 articles with zero comments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the articles with >64 into a df, then take a random sample of that frame\n",
    "# finally, put the article_text column for those into a string\n",
    "\n",
    "many_comments_df = socc_df[socc_df['ncomments'] > 64]\n",
    "sample_many_comments_df = many_comments_df.sample(n=100) \n",
    "many_comments = \", \".join(sample_many_comments_df['article_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "many_comments_df['ncomments'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "many_comments_df['ncomments'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the articles with 0 comments into a df, then take a random sample of that frame\n",
    "# finally, put the article_text column for those into a string\n",
    "\n",
    "zero_comments_df = socc_df[socc_df['ncomments'] == 0]\n",
    "sample_zero_comments_df = zero_comments_df.sample(n=100) \n",
    "zero_comments = \", \".join(sample_zero_comments_df['article_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_comments_df['ncomments'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleanup and analysis\n",
    "\n",
    "We have two string variables, `many_comments` and `zero_comments` (hint: if you get tired of typing variable names, you can start typing, hit \"tab\" and it will autocomplete.)\n",
    "\n",
    "The first thing we are going to do is look at the strings. You can check how long they are (this will be in characters) and print them, to see if they have any code we don't want. You'll see that there are `<p>` and `</p>` tags. Those are html paragraph marks, and we don't need them. So our first task is exciting: We'll define our first function! You'll see the line that starts with `def`. That's a function definition in python. We use the `re`, regular expression module, to find all the things between angle brackers, and replace them with nothing. Then, print the text again to see if they are gone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(many_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(zero_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(many_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(zero_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an HTML tag removal function\n",
    "\n",
    "def remove_html_tags(text):\n",
    "    clean = re.compile('<.*?>')\n",
    "    return re.sub(clean, '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "many_clean = remove_html_tags(many_comments)\n",
    "zero_clean = remove_html_tags(zero_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(many_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(many_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(zero_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spaCy\n",
    "\n",
    "We use spaCy to analyze the text. That'll give us tokens, POS, NER, etc. Go back to the `spacy_intro.ipynb` for information on the kind of information you can get from the spCy pipeline. I have given you just some examples again here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "many_doc = nlp(many_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_doc = nlp(zero_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some of the things from the other spacy notebook\n",
    "# I print only the first 20 tokens in many_doc\n",
    "\n",
    "for token in many_doc[:20]:\n",
    "    print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the entities in the first 50 tokens of zero_doc\n",
    "\n",
    "for ent in zero_doc[:50].ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare many and zero articles\n",
    "\n",
    "Think about what can make an article have many or no comments. Could it be the topics discussed? The author of the article? The people/places being discussed? We can try and compare these two very small samples using the information that spaCy provides and the information from the articles. \n",
    "\n",
    "The first comparison is not linguistic really, but about authors. Check which are the top 4-5 authors in each data sample and if they are significantly different. Note that, because we are taking a random sample from the `many_comments_df` and `zero_comments_df` every time we run this notebook, the results will change every time. You could also do this analysis on the full sample of each type. \n",
    "\n",
    "The next analysis compares the number of words and number of sentences in each sample (tokens in the article body). Are there differences? In my case, `many_doc` tends to have more tokens and sentences than `zero_doc`. \n",
    "\n",
    "Then, we are going to examine entities. One first analysis creates a dictionary and iterates through the list of entities, to see which entities are more frequent. We do the same for articles with zero comments. These will be long dictionaries, so it may be hard to find any differences. The next thing we do is to create lists of _types_ of entites, rather than the entities themselves. Do you see any differences? What are the top entities and top entity types in each corpus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_many_comments_df['author'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_zero_comments_df['author'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tokens in articles with many comments:\", len(many_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sentences in articles with many comments:\", len(list(many_doc.sents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tokens in articles with zero comments:\", len(zero_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sentences in articles with zero comments:\", len(list(zero_doc.sents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary to store the entities in the many_comments articles\n",
    "\n",
    "many_ent_dict = {}\n",
    "\n",
    "# iterate through the list of entities and increase the count every time\n",
    "# we see the same text\n",
    "\n",
    "for ent in many_doc.ents:\n",
    "    many_ent_dict[ent.text] = many_ent_dict.get(ent.text, 0) + 1\n",
    "\n",
    "# you can print many_ent_dict now, but it's not in sorted order\n",
    "# instead, create a sorted version of the dictionary and print that\n",
    "\n",
    "many_ent_dict_sorted = sorted(many_ent_dict.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "print(\"Entities in articles with many comments:\")\n",
    "for ent, count in many_ent_dict_sorted:\n",
    "    print(ent, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same for zero_comments\n",
    "\n",
    "zero_ent_dict = {}\n",
    "\n",
    "for ent in zero_doc.ents:\n",
    "    zero_ent_dict[ent.text] = zero_ent_dict.get(ent.text, 0) + 1\n",
    "\n",
    "zero_ent_dict_sorted = sorted(zero_ent_dict.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "print(\"Entities in articles with zero comments:\")\n",
    "for ent, count in zero_ent_dict_sorted:\n",
    "    print(ent, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, instead of the entities themselves, we are going to compare entity types\n",
    "many_ent_types = {}\n",
    "\n",
    "for ent in many_doc.ents:\n",
    "    many_ent_types[ent.label_] = many_ent_types.get(ent.label_, 0) + 1\n",
    "\n",
    "print(\"Entity types in articles with many comments:\")\n",
    "for ent, count in many_ent_types.items():\n",
    "    print(ent, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same for articles with zero comments\n",
    "zero_ent_types = {}\n",
    "\n",
    "for ent in zero_doc.ents:\n",
    "    zero_ent_types[ent.label_] = zero_ent_types.get(ent.label_, 0) + 1\n",
    "\n",
    "print(\"Entity types in articles with zero comments:\")\n",
    "for ent, count in zero_ent_types.items():\n",
    "    print(ent, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing top words and top POS\n",
    "\n",
    "What are the most frequent words, most frequent nouns, verbs, etc? Most frequent POS? To do this, it's best to work with the lemmatized versions, because then we can count _think, thought,_ and _thinking_ as instances of the same lemma, _think_. \n",
    "We will also use another tool, a list of [stop words](https://nlp.stanford.edu/IR-book/html/htmledition/dropping-common-terms-stop-words-1.html), so that we don't count frequent function words such as _the, and, of_. There are many such lists for English, depending on what you are interested in counting. The full list from spaCy is available on [spaCy's GitHub](https://github.com/explosion/spaCy/blob/master/spacy/lang/en/stop_words.py). We also exclude anything that is not a word, i.e., punctuation and numbers. These are the steps in the for loop to count lemmas:\n",
    "\n",
    "* First, check if it's an alpha type of token\n",
    "* Then, check that it is not a stop word\n",
    "* Lowercase the lemma\n",
    "* Add to the count of lemmas\n",
    "\n",
    "The next two code blocks count noun chunks, i.e., noun phrases. \n",
    "\n",
    "Then, we are going to work with POS tags. I'll do those in a separate section, because I also want to include plots and functions there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "many_lemma_counts = {}\n",
    "many_lemma_total = 0\n",
    "\n",
    "for token in many_doc:\n",
    "    if token.is_alpha and not token.is_stop:\n",
    "        lemma = token.lemma_.lower()\n",
    "        many_lemma_counts[lemma] = many_lemma_counts.get(lemma, 0) + 1\n",
    "        many_lemma_total = many_lemma_total + 1\n",
    "        \n",
    "many_lemma_counts_sorted = sorted(many_lemma_counts.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "print(\"Total lemma count: \", many_lemma_total)\n",
    "print(\"Lemmas in the many comments:\")\n",
    "for lemma, count in many_lemma_counts_sorted:\n",
    "    print(lemma, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same for zero comment articles\n",
    "\n",
    "zero_lemma_counts = {}\n",
    "zero_lemma_total = 0\n",
    "\n",
    "for token in zero_doc:\n",
    "    if token.is_alpha and not token.is_stop:\n",
    "        lemma = token.lemma_.lower()\n",
    "        zero_lemma_counts[lemma] = zero_lemma_counts.get(lemma, 0) + 1\n",
    "        zero_lemma_total = zero_lemma_total + 1\n",
    "        \n",
    "zero_lemma_counts_sorted = sorted(zero_lemma_counts.items(), key=lambda item: item[1], reverse=True)\n",
    "        \n",
    "print(\"Total lemmas: \", zero_lemma_total)\n",
    "\n",
    "print(\"Lemmas in the zero comments:\")\n",
    "for lemma, count in zero_lemma_counts_sorted:\n",
    "    print(lemma, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count noun chunks in many comment articles\n",
    "\n",
    "many_noun_chunk_counts = {}\n",
    "\n",
    "for noun_chunk in many_doc.noun_chunks:\n",
    "    noun_chunk_text = noun_chunk.text\n",
    "    many_noun_chunk_counts[noun_chunk_text] = many_noun_chunk_counts.get(noun_chunk_text, 0) + 1\n",
    "        \n",
    "many_noun_chunk_counts_sorted = sorted(many_noun_chunk_counts.items(), key=lambda item: item[1], reverse=True)\n",
    "        \n",
    "print(\"Noun chunk counts in the many comments:\")\n",
    "for noun_chunk, count in many_noun_chunk_counts_sorted:\n",
    "    print(noun_chunk, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count noun chunks in zero comment articles\n",
    "\n",
    "zero_noun_chunk_counts = {}\n",
    "\n",
    "for noun_chunk in zero_doc.noun_chunks:\n",
    "    noun_chunk_text = noun_chunk.text\n",
    "    zero_noun_chunk_counts[noun_chunk_text] = zero_noun_chunk_counts.get(noun_chunk_text, 0) + 1\n",
    "        \n",
    "zero_noun_chunk_counts_sorted = sorted(zero_noun_chunk_counts.items(), key=lambda item: item[1], reverse=True)\n",
    "        \n",
    "print(\"Noun chunk counts in the zero comments:\")\n",
    "for noun_chunk, count in zero_noun_chunk_counts_sorted:\n",
    "    print(noun_chunk, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS and plotting\n",
    "\n",
    "For POS tags, notice that we don't need to lowercase or lemmatize, as POS tags are already a sort of abstraction over those word-specific characteristics. \n",
    "\n",
    "We are also going to keep track of the total POS tags in each corpus. That will allow us to produce _normalized counts_ of the parts of speech. If we want to compare whether the many comments or the zero comments articles have, for instance, more nouns, we can't compare raw counts, because many articles may have more words, and therefore more POS instances (or vice versa). So we divide the count of each POS by the total number of POS in the corpus. \n",
    "\n",
    "There are many bases for normalization. A normalized frequency by 100 is just a percentage. But if you have a very large corpus (millions of words), then you do normalization by 1,000 or more. We'll do 100 here. \n",
    "\n",
    "Then, we can produce a pretty plot that compares the two corpora and the relative frequency of each type of POS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count parts of speech in many and also keep track of the total\n",
    "\n",
    "many_pos_counts = {}\n",
    "many_pos_total = 0\n",
    "\n",
    "for token in many_doc:\n",
    "    pos_tag = token.pos_\n",
    "    many_pos_counts[pos_tag] = many_pos_counts.get(pos_tag, 0) + 1\n",
    "    many_pos_total = many_pos_total + 1\n",
    "        \n",
    "many_pos_counts_sorted = sorted(many_pos_counts.items(), key=lambda item: item[1], reverse=True)\n",
    "        \n",
    "print(\"Total POS: \", many_pos_total)\n",
    "print(\"POS counts in the many comments:\")\n",
    "for pos, count in many_pos_counts_sorted:\n",
    "    print(pos, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count parts of speech in zero\n",
    "\n",
    "zero_pos_counts = {}\n",
    "zero_pos_total = 0\n",
    "\n",
    "for token in zero_doc:\n",
    "    pos_tag = token.pos_\n",
    "    zero_pos_counts[pos_tag] = zero_pos_counts.get(pos_tag, 0) + 1\n",
    "    zero_pos_total = zero_pos_total + 1\n",
    "        \n",
    "zero_pos_counts_sorted = sorted(zero_pos_counts.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "print(\"Total POS: \", zero_pos_total)\n",
    "print(\"POS counts in the zero comments:\")\n",
    "for pos, count in zero_pos_counts_sorted:\n",
    "    print(pos, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we normalize both dictionaries. I do by 100 and use the `round()` function to keep the percentage to two decimal points. I also sort the resulting dictionary by order of frequency, in descending order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "many_pos_norm = {}\n",
    "zero_pos_norm = {}\n",
    "\n",
    "for pos, count in many_pos_counts.items():\n",
    "    many_pos_norm[pos] = round((count / many_pos_total) * 100, 2)\n",
    "    \n",
    "many_pos_norm_sorted = dict(sorted(many_pos_norm.items(), key=lambda item: item[1], reverse=True))\n",
    "    \n",
    "for pos, count in zero_pos_counts.items():\n",
    "    zero_pos_norm[pos] = round((count / zero_pos_total) * 100, 2)\n",
    "    \n",
    "zero_pos_norm_sorted = dict(sorted(zero_pos_norm.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just look at the percentages in each\n",
    "\n",
    "for pos, perc in many_pos_norm_sorted.items():\n",
    "    print(pos, perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pos, perc in zero_pos_norm_sorted.items():\n",
    "    print(pos, perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the two dictionaries, side by side\n",
    "pos_list = list(many_pos_norm_sorted.keys())\n",
    "\n",
    "many_freq = [many_pos_norm_sorted.get(pos, 0) for pos in pos_list]\n",
    "zero_freq = [zero_pos_norm_sorted.get(pos, 0) for pos in pos_list]\n",
    "all_freq = many_freq + zero_freq\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bar_width = 0.4\n",
    "index = np.arange(len(pos_list))\n",
    "\n",
    "pos_with_labels = [pos + \"_1\" for pos in pos_list] + [pos + \"_2\" for pos in pos_list]\n",
    "\n",
    "plt.bar(index, many_freq, bar_width, color='blue', label='Many comments')\n",
    "plt.bar(index + bar_width, zero_freq, bar_width, color='brown', label='Zero comments')\n",
    "\n",
    "plt.xlabel('POS Tag')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('POS frequency in articles with many and with zero comments')\n",
    "plt.xticks(index + bar_width / 2, pos_list, rotation=45)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining functions\n",
    "\n",
    "A lot of what we have done above we have done for two different things, the many and the zero comment articles. That felt tedious, because we were just copy-pasting the same information, only changing the name of some variables. For that kind of situation, creating a generic function is much more efficient. \n",
    "\n",
    "Let's look at the `count_pos()` function. We define it using `def`. Then, we give it an argument, the doc (spaCy object) that contains our corpus processed by spaCy. \n",
    "\n",
    "Then, we do exactly the same thing we did above: we count the pos tags, we add up how many there are and sort that dictionary. At the end, the function prints the total number of POS tags and the list (a dictionary, really).\n",
    "\n",
    "To use the function, we simply call it with the right doc object. So, if we want to count the POS in many_comments, we pass that argument. And the same for zero comments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_pos(doc):\n",
    "    \n",
    "    pos_counts = {}\n",
    "    pos_total = 0\n",
    "    \n",
    "    for token in doc:\n",
    "        pos_tag = token.pos_\n",
    "        pos_counts[pos_tag] = pos_counts.get(pos_tag, 0) + 1\n",
    "        pos_total = pos_total + 1\n",
    "        \n",
    "    pos_counts_sorted = dict(sorted(pos_counts.items(), key = lambda item: item[1], reverse = True))\n",
    "    \n",
    "    return pos_counts_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To \"call\" this function, that is, to use this function, you simply type the name of the function and pass the variable that contains your corpus. Recall that this is `many_doc` and `zero_doc`, from above, the two docs that we produced with spaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_pos(many_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that only prints the dictionary from many_doc. If you want to store that dictionary to use later, then you assign it to a variable. This variable is exactly the same as the `many_pos_counts_sorted` above, but we produced it through a much more efficient way; that's why I'm calling it \"better\". And you can do the same for the `zero_doc`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "many_pos_counts_sorted_better = count_pos(many_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_pos_counts_sorted_better = count_pos(zero_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "many_pos_counts_sorted_better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_pos_counts_sorted_better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Your turn!\n",
    "\n",
    "Try it! Define a new function that doesn't do raw counts, but normalized counts, something like:\n",
    "\n",
    "`def pos_count_norm(doc):`\n",
    "\n",
    "Then you can probably turn most of the things we did twice, for many and for zero, into functions that you can reuse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
